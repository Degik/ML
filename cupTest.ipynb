{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class NeuralNetworkLayer(nn.Module):\n",
    "    def __init__(self, hidden_size:int):\n",
    "        super(NeuralNetworkLayer, self).__init__()\n",
    "\n",
    "        #Layer 1 Input: 10 Output: hidden_size\n",
    "        self.layer1 = nn.Linear(10, hidden_size)\n",
    "        #nn.init.kaiming_normal_(self.layer1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.uniform_(self.layer1.weight, -0.7, 0.7)\n",
    "        nn.init.constant_(self.layer1.bias, 0.01)\n",
    "        #Layer 3 Input: hidden_size Output: 3\n",
    "        self.layer2 = nn.Linear(hidden_size, 3)\n",
    "        #nn.init.kaiming_normal_(self.layer2.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.uniform_(self.layer2.weight, -0.7, 0.7)\n",
    "        nn.init.constant_(self.layer2.bias, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importDatasetCupInput(file_name:str, blind:bool) -> pd.DataFrame:\n",
    "    dataset = []\n",
    "    try:\n",
    "        dataset = pd.read_csv(file_name, header=None, dtype=float)\n",
    "    except Exception as e:\n",
    "        print(\"Error | Can not read dataset cup for take input\")\n",
    "        exit(1)\n",
    "    if not blind:\n",
    "        dataset = dataset.iloc[:, :-3] # Remove 3 columns\n",
    "    columns_name = ['ID'] + [f'X{i}' for i in range(1,11)]\n",
    "    dataset.columns = columns_name\n",
    "    dataset.set_index('ID', inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def importDatasetCupOutput(file_name:str, blind:bool) -> pd.DataFrame:\n",
    "    try:\n",
    "        dataset = pd.read_csv(file_name, header=None, dtype=float)\n",
    "    except Exception as e:\n",
    "        print(\"Error | Can not read dataset cup for take output\")\n",
    "        exit(1)\n",
    "    columns_list = ['ID', 'Y1', 'Y2', 'Y3']\n",
    "    if not blind: # Dataset with all inputs \n",
    "        indexes = [0, 10, 11, 12] # take the first and last 3 columns indexes\n",
    "        dataset = dataset.iloc[:, indexes]\n",
    "    dataset.columns = columns_list\n",
    "    dataset.set_index('ID', inplace=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch Params\n",
    "results = []\n",
    "hidden_sizes = [8,7,6,5]\n",
    "learning_rates = [0.01, 0.001, 0.05, 0.005]\n",
    "rates_split = [0.2, 0.25, 0.3]\n",
    "\n",
    "## TRAIN\n",
    "x_train = importDatasetCupInput(\"CUP/ML-CUP23-TRAIN.csv\", blind=False)\n",
    "y_train = importDatasetCupOutput(\"CUP/ML-CUP23-TRAIN.csv\", blind=False)\n",
    "\n",
    "## TEST\n",
    "x_test = importDatasetCupInput(\"CUP/ML-CUP23-TEST-INPUT.csv\", blind=True)\n",
    "y_test = importDatasetCupOutput(\"CUP/ML-CUP23-TEST-TARGET.csv\", blind=True)\n",
    "\n",
    "x_test = torch.tensor(x_test.to_numpy())\n",
    "y_test = torch.tensor(y_test.to_numpy())\n",
    "\n",
    "x_test = x_test.to(\"cuda:0\")\n",
    "y_test = y_test.to(\"cuda:0\")\n",
    "\n",
    "x_test = x_test.double()\n",
    "y_test = y_test.double()\n",
    "\n",
    "dataset_test = TensorDataset(x_test, y_test)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden_size:5, Learning-rate:0.005, Rate: 0.3 ,Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for hidden_size, learning_rate, rate in product(hidden_sizes, learning_rates, rates_split):\n",
    "\n",
    "    train_data, val_data, train_target, val_target = train_test_split(x_train, y_train, test_size=rate, random_state=40)\n",
    "\n",
    "    train_data, val_data, train_target, val_target = torch.tensor(train_data.to_numpy()), torch.tensor(val_data.to_numpy()), torch.tensor(train_target.to_numpy()), torch.tensor(val_target.to_numpy())\n",
    "\n",
    "    train_data, val_data, train_target, val_target = train_data.to(\"cuda:0\"), val_data.to(\"cuda:0\"), train_target.to(\"cuda:0\"), val_target.to(\"cuda:0\")\n",
    "\n",
    "    train_data, val_data, val_target, val_target = train_data.double(), val_data.double(), train_target.double(), val_target.double()\n",
    "\n",
    "    dataset_train = TensorDataset(train_data, train_target)\n",
    "    data_loader_train = DataLoader(dataset_train, batch_size=100, shuffle=True)\n",
    "\n",
    "    dataset_val = TensorDataset(val_data, val_target)\n",
    "    data_loader_val = DataLoader(dataset_val, batch_size=100, shuffle=True)\n",
    "\n",
    "    net = NeuralNetworkLayer(hidden_size)\n",
    "    net = net.to(\"cuda:0\")\n",
    "    net = net.double()\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_values = []\n",
    "    accuracy_values = []\n",
    "    epochs = 390\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_input, batch_output in data_loader_train:\n",
    "            #Forward pass\n",
    "            outputs = net(batch_input)\n",
    "            #Training loss\n",
    "            loss = criterion(outputs, batch_output)\n",
    "            #Calculate total loss\n",
    "            total_loss += loss.item()\n",
    "            #Backward and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader_train)\n",
    "        #Add to list\n",
    "        loss_values.append(avg_loss)\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_input, batch_output in data_loader_val:\n",
    "                predicted = net(batch_input)\n",
    "                total += batch_input.size(0)\n",
    "                correct += (predicted == batch_output).sum().item()\n",
    "            accuracy = correct / total\n",
    "            accuracy_values.append(accuracy)\n",
    "\n",
    "        net.train()\n",
    "\n",
    "    #Create dir\n",
    "    path_name = f'CUP/GridPlot/test-{hidden_size}-{learning_rate}-{rate}'\n",
    "    os.mkdir(path_name)\n",
    "    #Save plot loss\n",
    "    display.clear_output(wait=True)\n",
    "    plt.plot(loss_values, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{path_name}/Loss.png')\n",
    "    plt.clf()\n",
    "    #Save plot accuracy\n",
    "    display.clear_output(wait=True)\n",
    "    plt.plot(accuracy_values, label='Accuracy Test')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy for Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{path_name}/Accuracy-test.png')\n",
    "    plt.clf()\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_input, batch_output in data_loader_test:\n",
    "            predicted = net(batch_input)\n",
    "            total += batch_input.size(0)\n",
    "            correct += (predicted == batch_output).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    result = f'Hidden_size:{hidden_size}, Learning-rate:{learning_rate}, Rate: {rate} ,Accuracy: {accuracy:.4f}'\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "\n",
    "with open(\"resultsCUP.txt\", 'w') as file:\n",
    "    for result in results:\n",
    "        file.write(result + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
